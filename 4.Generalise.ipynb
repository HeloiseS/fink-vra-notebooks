{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef5dcff",
   "metadata": {},
   "source": [
    "# Generalise and modularise the code\n",
    "\n",
    "Now that I can make features, run the initialising loop and the subesquent loops, and that I'm played with ML Flow, it's time to make more general and modular code that can go in `finkvra` and be called in smaller script. \n",
    "\n",
    "Also should be able to use config files to set up experiments more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45fb15df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "from datetime import datetime\n",
    "import os\n",
    "from finkvra.utils.features import make_features as fvra_make_features\n",
    "from finkvra.utils.labels import cli_label_one_object as fvra_cli_label_one_object\n",
    "import json\n",
    "from mlflow.tracking import MlflowClient\n",
    "import logging\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.WARNING, \n",
    "                    format=\"%(asctime)s [%(levelname)s] %(name)s.%(funcName)s: %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78ff32",
   "metadata": {},
   "source": [
    "# Step-by-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e7e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Should go somewhere in finkvra? or as class attributes?\n",
    "\n",
    "label2galclass = {'real': np.nan,\n",
    "                  'extragal': 0,\n",
    "                  'gal': 1,\n",
    "                  'agn': 0,\n",
    "                  'bogus': np.nan,\n",
    "                  'varstar': 1,\n",
    "                  None: np.nan,\n",
    "                  np.nan: np.nan,\n",
    "                 }\n",
    "\n",
    "label2realclass = {'real': 1,\n",
    "                  'extragal': 1,\n",
    "                  'gal': 1,\n",
    "                  'agn': 1,\n",
    "                  'bogus': 0,\n",
    "                  'varstar': 1,\n",
    "                  None: np.nan,\n",
    "                  np.nan: np.nan,\n",
    "                 }\n",
    "\n",
    "label2transclass = {'real': np.nan,\n",
    "                  'extragal': 1,\n",
    "                  'gal': 1,\n",
    "                  'agn': 0,\n",
    "                  'bogus': np.nan,\n",
    "                  'varstar': 0,\n",
    "                  None: np.nan,\n",
    "                  np.nan: np.nan,\n",
    "                 }\n",
    "\n",
    "label2class = {'gal': label2galclass,\n",
    "               'real': label2realclass,\n",
    "               'trans': label2transclass\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c7ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:31:50,316 [WARNING] __main__.<module>: Output directory /home/stevance/Science/fink-vra-notebooks/test_outputs/SEP25gal_model_AL does not exist. Creating it.\n"
     ]
    }
   ],
   "source": [
    "## CONFIG - TO REPLACE BY READING A JSON FILE - these will be dafault but should have CL args for e.g parquet_paths\n",
    "EXPERIMENT = \"SEP25gal_model_AL\"#\"test_experiment\" \n",
    "SAMPLING_STRATEGY = \"uncertainty\"\n",
    "HOST = \"127.0.0.1\"\n",
    "PORT = \"6969\"\n",
    "PARQUET_GLOB_PATH = '/home/stevance/Data/FinkZTFStream/*.parquet' #None # if not given prompt user \n",
    "#PARQUET_GLOB_PATH = '/home/stevance/Data/FinkZTFStream/20250602*.parquet'\n",
    "\n",
    "# TODO: CHECK MODEL TYPE IS gal, real or trans\n",
    "MODEL_TYPE = 'gal'\n",
    "LABELS_PATH = '/home/stevance/Data/FinkZTFStream/labeled.csv'\n",
    "OUTPUT_ROOT = '/home/stevance/Science/fink-vra-notebooks/test_outputs/'\n",
    "N_batch_0 = 30 # first batch size\n",
    "N_batch_i = 5 # subsequent batches\n",
    "\n",
    "PARAMS={\n",
    "    \"l2_regularization\": 10,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "# Check if the {OUTPUT_ROOT}{EXPERIMENT} directory exists, if not create it\n",
    "if not os.path.exists(f\"{OUTPUT_ROOT}{EXPERIMENT}\"):\n",
    "    # log a warning and then create the directory\n",
    "    logger.warning(f\"Output directory {OUTPUT_ROOT}{EXPERIMENT} does not exist. Creating it.\")\n",
    "    os.makedirs(f\"{OUTPUT_ROOT}{EXPERIMENT}\")\n",
    "\n",
    "# +++++++++++++++++++++\n",
    "# Constants from Config\n",
    "# +++++++++++++++++++++\n",
    "\n",
    "model_subpath = f\"{MODEL_TYPE}_model\"\n",
    "training_ids_path = f\"{OUTPUT_ROOT}{EXPERIMENT}/{SAMPLING_STRATEGY}_{MODEL_TYPE}_training_ids.csv\"\n",
    "training_ids_artifact_path = f\"{SAMPLING_STRATEGY}_{MODEL_TYPE}_training_ids.csv\"\n",
    "labels = pd.read_csv(LABELS_PATH, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf928b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +++++++++++++++++++++\n",
    "# ML Flow set up\n",
    "# +++++++++++++++++++++\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{HOST}:{PORT}\")\n",
    "mlflow.set_experiment(EXPERIMENT)\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT)\n",
    "\n",
    "# Get the run idea of the last SUCCESSFUL run\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"attributes.status = 'FINISHED'\",\n",
    "    order_by=[\"start_time DESC\"],\n",
    "    max_results=1,\n",
    ")\n",
    "\n",
    "mlflow_uri = mlflow.get_tracking_uri()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e3e7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ids_artifact_path = \"training_ids.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2844df2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:35:44,647 [INFO] __main__.<module>: Found Successful run - ID: 4e2766df1a5f466f9aab9d5eb9d62c64. Batch size is 5\n",
      "2025-09-30 15:35:44,648 [INFO] __main__.<module>: Loading artifacts from previous run: Previous training IDs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5ef90c62324a2690d94466081f7d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:35:44,664 [INFO] __main__.<module>: Previous trainings IDs found - CURRENT ROUND: 4\n",
      "2025-09-30 15:35:44,665 [INFO] __main__.<module>: Loading artifacts from previous run: Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c08f59fe6c4a93b142da142211a8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# +++++++++++++++++++++++++++++++++++++\n",
    "# Load artifacts and set ROUND number\n",
    "# ++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "if not runs:\n",
    "    CURRENT_ROUND = 0\n",
    "    BATCH_SIZE = N_batch_0\n",
    "    logger.info(f\"This is ROUND 0 of EXPERIMENT {EXPERIMENT}. Batch size is {BATCH_SIZE}\")\n",
    "else:\n",
    "    last_run = runs[0]\n",
    "    prev_run_id = last_run.info.run_id\n",
    "    BATCH_SIZE = N_batch_i\n",
    "    logger.info(f\"Found Successful run - ID: {prev_run_id}. Batch size is {BATCH_SIZE}\")\n",
    "    \n",
    "    \n",
    "    logger.info(f\"Loading artifacts from previous run: Previous training IDs\")\n",
    "    previous_ids_path = client.download_artifacts(prev_run_id, training_ids_artifact_path)\n",
    "    previous_ids_df = pd.read_csv(previous_ids_path)\n",
    "    CURRENT_ROUND= previous_ids_df.iloc[-1]['round'] + 1\n",
    "    logger.info(f\"Previous trainings IDs found - CURRENT ROUND: {CURRENT_ROUND}\")\n",
    "                \n",
    "    logger.info(f\"Loading artifacts from previous run: Model\")\n",
    "    model_uri = f\"runs:/{prev_run_id}/{model_subpath}\"\n",
    "    clf = mlflow.sklearn.load_model(model_uri)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2064eee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:44:31,394 [INFO] __main__.<module>: 408 .parquet files loaded from /home/stevance/Data/FinkZTFStream/*.parquet\n",
      "2025-09-30 15:47:18,628 [INFO] __main__.<module>: Features made for 6217 samples (unique candid) - 4414 unique objects\n"
     ]
    }
   ],
   "source": [
    "# ++++++++++++++++++++++++++++++++++++\n",
    "# Load Parquet and Make Features\n",
    "# +++++++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "files = sorted(glob(PARQUET_GLOB_PATH))\n",
    "dfs = [pd.read_parquet(f) for f in files]\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "logger.info(f\"{len(files)} .parquet files loaded from {PARQUET_GLOB_PATH}\")\n",
    "\n",
    "\n",
    "X, meta = fvra_make_features(data)\n",
    "# remove samples that have no positive detections\n",
    "valid_candid = list(X[X.ndets > 0].index.values)\n",
    "X = X.loc[valid_candid]\n",
    "meta = meta.loc[valid_candid]\n",
    "logger.info(f\"Features made for {X.shape[0]} samples (unique candid) - {meta.objectId.unique().shape[0]} unique objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bae485a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# REMOVE AFTER TESTING\n",
    "#X = X.drop('ebv', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9234d1f9",
   "metadata": {},
   "source": [
    "### Here only happens if not round 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c950f08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:47:55,058 [INFO] __main__.<module>: Training pool contains 6147 samples (4377 unique)\n",
      "2025-09-30 15:47:55,059 [INFO] __main__.<module>: Predicting class for training pool using previous model\n",
      "/home/stevance/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but HistGradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if CURRENT_ROUND > 0:\n",
    "    # TODO - turn this into a function?\n",
    "    train_ids = previous_ids_df[\"candid\"].tolist()\n",
    "    X_pool = X.drop(index=train_ids, errors='ignore')\n",
    "    \n",
    "    meta_pool = meta.drop(index=train_ids, errors='ignore')\n",
    "    logger.info(f\"Training pool contains {X_pool.shape[0]} samples ({meta_pool.objectId.unique().shape[0]} unique)\")\n",
    "    \n",
    "    logger.info(f\"Predicting class for training pool using previous model\")\n",
    "    y_pred = clf.predict_proba(X_pool)[:, 1]  \n",
    "    y_pred_pool = pd.DataFrame( np.vstack((X_pool.index.values.astype(str), y_pred)).T, columns= ['candid', 'pred']).set_index('candid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca656d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 6. Active Learning sampling with dynamic labeling\n",
    "# ----------------------------------------------------\n",
    "\n",
    "### here need a function that gives back sampling score: low is \"good\" (we want)\n",
    "y_pred_pool['sampling_score'] = np.abs(y_pred_pool[\"pred\"].astype(float) - 0.5) \n",
    "y_pred_pool.sort_values('sampling_score', ascending=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b17619cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "candid_loop = y_pred_pool.index.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0f9f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CURRENT_ROUND == 0:\n",
    "    # could scramble them if you wanted more randomness\n",
    "    candid_loop = X.index.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a333a",
   "metadata": {},
   "source": [
    "### This happens too if ROUND 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1564d9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Object: ZTF19abiwysm\n",
      "Opening https://lasair-ztf.lsst.ac.uk/objects/ZTF19abiwysm...\n",
      "Label [r/x/g/a/b/v] (s=skip, q=quit): x\n",
      "Labeled as 'extragal'\n",
      "\n",
      " Object: ZTF20abaowcx\n",
      "Opening https://lasair-ztf.lsst.ac.uk/objects/ZTF20abaowcx...\n",
      "Label [r/x/g/a/b/v] (s=skip, q=quit): a\n",
      "Labeled as 'agn'\n",
      "\n",
      " Object: ZTF20abaowcx\n",
      "Opening https://lasair-ztf.lsst.ac.uk/objects/ZTF20abaowcx...\n",
      "Label [r/x/g/a/b/v] (s=skip, q=quit): a\n",
      "Labeled as 'agn'\n",
      "\n",
      " Object: ZTF25abboazq\n",
      "Opening https://lasair-ztf.lsst.ac.uk/objects/ZTF25abboazq...\n",
      "Label [r/x/g/a/b/v] (s=skip, q=quit): x\n",
      "Labeled as 'extragal'\n",
      "\n",
      " Object: ZTF25absbrai\n",
      "Opening https://lasair-ztf.lsst.ac.uk/objects/ZTF25absbrai...\n",
      "Label [r/x/g/a/b/v] (s=skip, q=quit): x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:50:07,242 [INFO] root.<module>: Batch size (5) reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled as 'extragal'\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# Labeling\n",
    "# ----------------------------------------------------\n",
    "\n",
    "new_labels = []\n",
    "new_label_candid = []\n",
    "new_sample_candid = []\n",
    "\n",
    "N_i = 0\n",
    "\n",
    "for _candid in candid_loop:\n",
    "    try: \n",
    "        try:\n",
    "            classification = label2galclass[labels.loc[_candid].label]\n",
    "        except TypeError:\n",
    "            logging.error(f\"Shit! You got duplicate labels in {LABELS_PATH}\")\n",
    "            logging.error(_candid)\n",
    "            exit()\n",
    "        if not np.isnan(classification):\n",
    "            new_sample_candid.append(_candid)\n",
    "            N_i += 1\n",
    "    except KeyError: \n",
    "        # if _candid not in labels then labels.loc[_candid] will throw a KeyError \n",
    "        # and we can activate the logic below\n",
    "        _objectId = meta.loc[_candid].objectId\n",
    "        \n",
    "        # this is where we need the labeling \n",
    "        label = fvra_cli_label_one_object(_objectId)\n",
    "        \n",
    "        if label is None: \n",
    "            continue\n",
    "        new_labels.append(label)\n",
    "        new_label_candid.append(_candid)\n",
    "        classification = label2galclass[label]\n",
    "        if not np.isnan(classification):\n",
    "            new_sample_candid.append(_candid)\n",
    "            N_i += 1\n",
    "        \n",
    "    if N_i == BATCH_SIZE:\n",
    "        logging.info(f'Batch size ({BATCH_SIZE}) reached.')\n",
    "        break\n",
    "\n",
    "if N_i < BATCH_SIZE:\n",
    "    logging.warning(f'Batch size ({BATCH_SIZE}) not reached: {N_i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f4453ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:50:17,255 [INFO] root.<module>: Updated the labels at: /home/stevance/Data/FinkZTFStream/labeled.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectId</th>\n",
       "      <th>label</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3069386410515015007</th>\n",
       "      <td>ZTF19aarxyde</td>\n",
       "      <td>varstar</td>\n",
       "      <td>2025-06-02T08:37:22.993787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069386415315015051</th>\n",
       "      <td>ZTF25aastlyj</td>\n",
       "      <td>real</td>\n",
       "      <td>2025-06-02T08:38:09.167712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069382582215015014</th>\n",
       "      <td>ZTF25aastlfp</td>\n",
       "      <td>varstar</td>\n",
       "      <td>2025-06-02T08:38:35.964541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069388402015015013</th>\n",
       "      <td>ZTF25aastlnm</td>\n",
       "      <td>varstar</td>\n",
       "      <td>2025-06-02T08:38:48.162550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069382583515015017</th>\n",
       "      <td>ZTF25aastmlg</td>\n",
       "      <td>varstar</td>\n",
       "      <td>2025-06-02T09:44:44.227317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181330900815015002</th>\n",
       "      <td>ZTF19abiwysm</td>\n",
       "      <td>extragal</td>\n",
       "      <td>2025-09-30T14:50:17.254649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116222901915015000</th>\n",
       "      <td>ZTF20abaowcx</td>\n",
       "      <td>agn</td>\n",
       "      <td>2025-09-30T14:50:17.254649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133242891915015004</th>\n",
       "      <td>ZTF20abaowcx</td>\n",
       "      <td>agn</td>\n",
       "      <td>2025-09-30T14:50:17.254649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127277780015015036</th>\n",
       "      <td>ZTF25abboazq</td>\n",
       "      <td>extragal</td>\n",
       "      <td>2025-09-30T14:50:17.254649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184203064615015016</th>\n",
       "      <td>ZTF25absbrai</td>\n",
       "      <td>extragal</td>\n",
       "      <td>2025-09-30T14:50:17.254649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         objectId     label                   timestamp\n",
       "candid                                                                 \n",
       "3069386410515015007  ZTF19aarxyde   varstar  2025-06-02T08:37:22.993787\n",
       "3069386415315015051  ZTF25aastlyj      real  2025-06-02T08:38:09.167712\n",
       "3069382582215015014  ZTF25aastlfp   varstar  2025-06-02T08:38:35.964541\n",
       "3069388402015015013  ZTF25aastlnm   varstar  2025-06-02T08:38:48.162550\n",
       "3069382583515015017  ZTF25aastmlg   varstar  2025-06-02T09:44:44.227317\n",
       "...                           ...       ...                         ...\n",
       "3181330900815015002  ZTF19abiwysm  extragal  2025-09-30T14:50:17.254649\n",
       "3116222901915015000  ZTF20abaowcx       agn  2025-09-30T14:50:17.254649\n",
       "3133242891915015004  ZTF20abaowcx       agn  2025-09-30T14:50:17.254649\n",
       "3127277780015015036  ZTF25abboazq  extragal  2025-09-30T14:50:17.254649\n",
       "3184203064615015016  ZTF25absbrai  extragal  2025-09-30T14:50:17.254649\n",
       "\n",
       "[133 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# Update label\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "timestamp = datetime.utcnow().isoformat()\n",
    "new_labels_df = pd.DataFrame.from_dict({\n",
    "                                         'objectId': meta.loc[np.array(new_label_candid).astype(np.int64)].objectId,\n",
    "                                          'label':  new_labels,\n",
    "                                        'timestamp': timestamp\n",
    "                                       })\n",
    "updated_labels = pd.concat((labels, new_labels_df))\n",
    "\n",
    "logging.info(f\"Updated the labels at: {LABELS_PATH}\")\n",
    "updated_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5222749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Candids for training\n",
    "# ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b44b47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids_df = pd.DataFrame({'candid': np.array(new_sample_candid).astype(np.int64),\n",
    "                           'round': CURRENT_ROUND,\n",
    "                          })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23167c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:50:19,553 [INFO] root.<module>: Saved training ids locally to /home/stevance/Science/fink-vra-notebooks/test_outputs/SEP25gal_model_AL/uncertainty_gal_training_ids.csv\n"
     ]
    }
   ],
   "source": [
    "if CURRENT_ROUND > 0:\n",
    "    train_ids_df = pd.concat([previous_ids_df, new_ids_df]).reset_index(drop=True)\n",
    "else:\n",
    "    train_ids_df = new_ids_df\n",
    "    \n",
    "train_ids_df.to_csv(training_ids_path, index=False)\n",
    "logging.info(f'Saved training ids locally to {training_ids_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "027ec27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:50:20,192 [INFO] __main__.<module>: Made y_train and X_train and saved to /home/stevance/Science/fink-vra-notebooks/test_outputs/SEP25gal_model_AL\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# 7. Make the y_train X_train for new round\n",
    "# -------------------\n",
    "\n",
    "\n",
    "y_train = updated_labels.loc[train_ids_df.candid].label.map(label2class[MODEL_TYPE])\n",
    "X_train = X.loc[train_ids_df.candid]\n",
    "\n",
    "y_train.to_csv(f\"{OUTPUT_ROOT}{EXPERIMENT}/y_train_R{CURRENT_ROUND}.csv\")\n",
    "X_train.to_csv(f\"{OUTPUT_ROOT}{EXPERIMENT}/X_train_R{CURRENT_ROUND}.csv\")\n",
    "\n",
    "logger.info(f\"Made y_train and X_train and saved to {OUTPUT_ROOT}{EXPERIMENT}\")\n",
    "\n",
    "# Make the signature for ML Flow\n",
    "signature = infer_signature(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a73d87a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>drb</th>\n",
       "      <th>ndets</th>\n",
       "      <th>nnondets</th>\n",
       "      <th>dets_median</th>\n",
       "      <th>dets_std</th>\n",
       "      <th>sep_arcsec</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>linear_fit_reduced_chi2</th>\n",
       "      <th>...</th>\n",
       "      <th>linear_fit_slope_sigma</th>\n",
       "      <th>median</th>\n",
       "      <th>median_absolute_deviation</th>\n",
       "      <th>amplituder_</th>\n",
       "      <th>linear_fit_reduced_chi2r_</th>\n",
       "      <th>linear_fit_sloper_</th>\n",
       "      <th>linear_fit_slope_sigmar_</th>\n",
       "      <th>medianr_</th>\n",
       "      <th>median_absolute_deviationr_</th>\n",
       "      <th>ebv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3069386410515015007</th>\n",
       "      <td>286.972916</td>\n",
       "      <td>60.047391</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.475401</td>\n",
       "      <td>0.075382</td>\n",
       "      <td>0.42265986534096434</td>\n",
       "      <td>0.070496</td>\n",
       "      <td>0.069703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>19.842197</td>\n",
       "      <td>0.018932</td>\n",
       "      <td>0.070496</td>\n",
       "      <td>0.069703</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>19.842197</td>\n",
       "      <td>0.018932</td>\n",
       "      <td>0.075731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069382582215015014</th>\n",
       "      <td>293.757494</td>\n",
       "      <td>24.732624</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.765827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.2398935354229732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.765827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.765827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069388402015015013</th>\n",
       "      <td>334.137737</td>\n",
       "      <td>46.956847</td>\n",
       "      <td>0.995750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.520535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0563054064397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.520535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.520535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069382583515015017</th>\n",
       "      <td>296.641470</td>\n",
       "      <td>26.630707</td>\n",
       "      <td>0.951255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.625126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.1566587143809444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.625126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.625126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.957513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069386414215015010</th>\n",
       "      <td>283.759268</td>\n",
       "      <td>62.913423</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.100019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.758135128184068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.690671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.690671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181330900815015002</th>\n",
       "      <td>354.538879</td>\n",
       "      <td>-4.852683</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>59.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.170601</td>\n",
       "      <td>0.361792</td>\n",
       "      <td>0.5640928936115532</td>\n",
       "      <td>0.099112</td>\n",
       "      <td>0.568047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>17.887769</td>\n",
       "      <td>0.028824</td>\n",
       "      <td>0.099112</td>\n",
       "      <td>0.568047</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>17.887769</td>\n",
       "      <td>0.028824</td>\n",
       "      <td>0.036027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116222901915015000</th>\n",
       "      <td>266.529418</td>\n",
       "      <td>60.919060</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.035700</td>\n",
       "      <td>0.129517</td>\n",
       "      <td>0.11000687071166554</td>\n",
       "      <td>0.203163</td>\n",
       "      <td>0.230237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>19.964101</td>\n",
       "      <td>0.049046</td>\n",
       "      <td>0.203163</td>\n",
       "      <td>0.230237</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>19.964101</td>\n",
       "      <td>0.049046</td>\n",
       "      <td>0.047259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133242891915015004</th>\n",
       "      <td>266.529522</td>\n",
       "      <td>60.919082</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.034224</td>\n",
       "      <td>0.135806</td>\n",
       "      <td>0.11175345878539097</td>\n",
       "      <td>0.203163</td>\n",
       "      <td>0.248353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>19.984800</td>\n",
       "      <td>0.058260</td>\n",
       "      <td>0.203163</td>\n",
       "      <td>0.248353</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>19.984800</td>\n",
       "      <td>0.058260</td>\n",
       "      <td>0.047255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127277780015015036</th>\n",
       "      <td>290.458985</td>\n",
       "      <td>-26.727137</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.520500</td>\n",
       "      <td>0.210759</td>\n",
       "      <td>2.4959839018887138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184203064615015016</th>\n",
       "      <td>310.152222</td>\n",
       "      <td>33.909342</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>19.844307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.9947496432796439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ra        dec       drb  ndets  nnondets  \\\n",
       "candid                                                                  \n",
       "3069386410515015007  286.972916  60.047391  0.999990   11.0       6.0   \n",
       "3069382582215015014  293.757494  24.732624  0.999734    1.0      17.0   \n",
       "3069388402015015013  334.137737  46.956847  0.995750    1.0      16.0   \n",
       "3069382583515015017  296.641470  26.630707  0.951255    1.0      16.0   \n",
       "3069386414215015010  283.759268  62.913423  0.999961    1.0      16.0   \n",
       "...                         ...        ...       ...    ...       ...   \n",
       "3181330900815015002  354.538879  -4.852683  0.999998   59.0      17.0   \n",
       "3116222901915015000  266.529418  60.919060  0.999972   51.0       9.0   \n",
       "3133242891915015004  266.529522  60.919082  0.999981   41.0       6.0   \n",
       "3127277780015015036  290.458985 -26.727137  0.999925    9.0      35.0   \n",
       "3184203064615015016  310.152222  33.909342  0.999923    1.0      42.0   \n",
       "\n",
       "                     dets_median  dets_std           sep_arcsec  amplitude  \\\n",
       "candid                                                                       \n",
       "3069386410515015007    20.475401  0.075382  0.42265986534096434   0.070496   \n",
       "3069382582215015014    19.765827  0.000000   1.2398935354229732   0.000000   \n",
       "3069388402015015013    19.520535  0.000000      9.0563054064397   0.000000   \n",
       "3069382583515015017    19.625126  0.000000   3.1566587143809444   0.000000   \n",
       "3069386414215015010    20.100019  0.000000    5.758135128184068   0.000000   \n",
       "...                          ...       ...                  ...        ...   \n",
       "3181330900815015002    19.170601  0.361792   0.5640928936115532   0.099112   \n",
       "3116222901915015000    20.035700  0.129517  0.11000687071166554   0.203163   \n",
       "3133242891915015004    20.034224  0.135806  0.11175345878539097   0.203163   \n",
       "3127277780015015036    19.520500  0.210759   2.4959839018887138        NaN   \n",
       "3184203064615015016    19.844307  0.000000   1.9947496432796439        NaN   \n",
       "\n",
       "                     linear_fit_reduced_chi2  ...  linear_fit_slope_sigma  \\\n",
       "candid                                        ...                           \n",
       "3069386410515015007                 0.069703  ...                0.004152   \n",
       "3069382582215015014                      NaN  ...                     NaN   \n",
       "3069388402015015013                      NaN  ...                     NaN   \n",
       "3069382583515015017                      NaN  ...                     NaN   \n",
       "3069386414215015010                      NaN  ...                     NaN   \n",
       "...                                      ...  ...                     ...   \n",
       "3181330900815015002                 0.568047  ...                0.001139   \n",
       "3116222901915015000                 0.230237  ...                0.003956   \n",
       "3133242891915015004                 0.248353  ...                0.004904   \n",
       "3127277780015015036                      NaN  ...                     NaN   \n",
       "3184203064615015016                      NaN  ...                     NaN   \n",
       "\n",
       "                        median  median_absolute_deviation  amplituder_  \\\n",
       "candid                                                                   \n",
       "3069386410515015007  19.842197                   0.018932     0.070496   \n",
       "3069382582215015014  19.765827                   0.000000     0.000000   \n",
       "3069388402015015013  19.520535                   0.000000     0.000000   \n",
       "3069382583515015017  19.625126                   0.000000     0.000000   \n",
       "3069386414215015010  19.690671                   0.000000     0.000000   \n",
       "...                        ...                        ...          ...   \n",
       "3181330900815015002  17.887769                   0.028824     0.099112   \n",
       "3116222901915015000  19.964101                   0.049046     0.203163   \n",
       "3133242891915015004  19.984800                   0.058260     0.203163   \n",
       "3127277780015015036        NaN                        NaN          NaN   \n",
       "3184203064615015016        NaN                        NaN          NaN   \n",
       "\n",
       "                     linear_fit_reduced_chi2r_  linear_fit_sloper_  \\\n",
       "candid                                                               \n",
       "3069386410515015007                   0.069703            0.003666   \n",
       "3069382582215015014                        NaN                 NaN   \n",
       "3069388402015015013                        NaN                 NaN   \n",
       "3069382583515015017                        NaN                 NaN   \n",
       "3069386414215015010                        NaN                 NaN   \n",
       "...                                        ...                 ...   \n",
       "3181330900815015002                   0.568047            0.001392   \n",
       "3116222901915015000                   0.230237           -0.000406   \n",
       "3133242891915015004                   0.248353           -0.000010   \n",
       "3127277780015015036                        NaN                 NaN   \n",
       "3184203064615015016                        NaN                 NaN   \n",
       "\n",
       "                     linear_fit_slope_sigmar_   medianr_  \\\n",
       "candid                                                     \n",
       "3069386410515015007                  0.004152  19.842197   \n",
       "3069382582215015014                       NaN  19.765827   \n",
       "3069388402015015013                       NaN  19.520535   \n",
       "3069382583515015017                       NaN  19.625126   \n",
       "3069386414215015010                       NaN  19.690671   \n",
       "...                                       ...        ...   \n",
       "3181330900815015002                  0.001139  17.887769   \n",
       "3116222901915015000                  0.003956  19.964101   \n",
       "3133242891915015004                  0.004904  19.984800   \n",
       "3127277780015015036                       NaN        NaN   \n",
       "3184203064615015016                       NaN        NaN   \n",
       "\n",
       "                     median_absolute_deviationr_       ebv  \n",
       "candid                                                      \n",
       "3069386410515015007                     0.018932  0.075731  \n",
       "3069382582215015014                     0.000000  1.916294  \n",
       "3069388402015015013                     0.000000  0.159215  \n",
       "3069382583515015017                     0.000000  2.957513  \n",
       "3069386414215015010                     0.000000  0.079199  \n",
       "...                                          ...       ...  \n",
       "3181330900815015002                     0.028824  0.036027  \n",
       "3116222901915015000                     0.049046  0.047259  \n",
       "3133242891915015004                     0.058260  0.047255  \n",
       "3127277780015015036                          NaN  0.117575  \n",
       "3184203064615015016                          NaN  0.694415  \n",
       "\n",
       "[75 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9fe2c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_artifact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d29b880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l2_regularization': 10, 'learning_rate': 0.1, 'random_state': 42}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d83329c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stevance/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but HistGradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run round_4_uncertainty at: http://127.0.0.1:6969/#/experiments/575240719855823327/runs/14edd4ff4a1f4ca1b428c6bffffc295e\n",
      "🧪 View experiment at: http://127.0.0.1:6969/#/experiments/575240719855823327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stevance/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but HistGradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------\n",
    "# 8. Train!\n",
    "# -------------------\n",
    "\n",
    "MODEL_TAG = f\"{model_subpath}_round_{CURRENT_ROUND}\"\n",
    "\n",
    "with mlflow.start_run(run_name=f\"round_{CURRENT_ROUND}_{SAMPLING_STRATEGY}\"):\n",
    "\n",
    "    # Log metadata\n",
    "    meta_info = {\n",
    "        \"round\": int(CURRENT_ROUND),\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"n_train\": int(X_train.shape[0]),\n",
    "        \"sampling_strategy\": str(SAMPLING_STRATEGY),\n",
    "        \"model_tag\": str(MODEL_TAG)\n",
    "    }\n",
    "\n",
    "    with open(\"meta.json\", \"w\") as f:\n",
    "        json.dump(meta_info, f, indent=2)\n",
    "    mlflow.log_artifact(\"meta.json\")\n",
    "\n",
    "    # Train model\n",
    "    mlflow.log_params(PARAMS)\n",
    "    clf_new = HistGradientBoostingClassifier(**PARAMS)\n",
    "    clf_new.fit(X_train.values, y_train.values)\n",
    "\n",
    "    # Evaluate on training set\n",
    "    acc = accuracy_score(y_train, clf_new.predict(X_train.values))\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    \n",
    "    prec = precision_score(y_train, clf_new.predict(X_train.values))\n",
    "    mlflow.log_metric(\"precision\", prec)\n",
    "    \n",
    "    recall = recall_score(y_train, clf_new.predict(X_train.values))\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    \n",
    "    f1 = f1_score(y_train, clf_new.predict(X_train.values))\n",
    "    mlflow.log_metric(\"f1-score\", f1)\n",
    "\n",
    "    # Log model\n",
    "    signature = infer_signature(X_train, clf_new.predict(X_train))\n",
    "    mlflow.sklearn.log_model(\n",
    "        clf_new,\n",
    "        artifact_path=model_subpath,\n",
    "        signature=signature,\n",
    "        input_example=X_train.iloc[:2]\n",
    "    )\n",
    "\n",
    "    # Save training state\n",
    "    mlflow.log_artifact(training_ids_path)\n",
    "    mlflow.log_artifact(f\"{OUTPUT_ROOT}{EXPERIMENT}/y_train_R{CURRENT_ROUND}.csv\")\n",
    "    mlflow.log_artifact(f\"{OUTPUT_ROOT}{EXPERIMENT}/X_train_R{CURRENT_ROUND}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d01512e",
   "metadata": {},
   "source": [
    "# Dev in `finkvra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2cc94f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fcdc1bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finkvra.alonstream.alpipeline import ALPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5d883dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 07:16:38,572 [INFO] finkvra.alonstream.alpipeline.__init__: Settings loaded from ./testconfigfile.yaml\n",
      "2025-06-06 07:16:38,585 [INFO] finkvra.alonstream.alpipeline.__mlflow_setup: This is ROUND 0 of EXPERIMENT teeeeest. Batch size is 30\n",
      "2025-06-06 07:16:38,585 [INFO] finkvra.alonstream.alpipeline.__init__: ML Flow set-up complete.\n",
      "2025-06-06 07:16:38,585 [INFO] finkvra.alonstream.alpipeline.__load_parquet: Loading parquet files from /home/stevance/Data/FinkZTFStream/*.parquet\n",
      "2025-06-06 07:16:38,883 [INFO] finkvra.alonstream.alpipeline.__load_parquet: 88 .parquet files loaded from /home/stevance/Data/FinkZTFStream/*.parquet\n",
      "2025-06-06 07:16:42,373 [INFO] finkvra.alonstream.alpipeline.__init__: Features made for 140 samples (unique candid) - 138 unique objects\n",
      "2025-06-06 07:16:42,374 [INFO] root.__labeling: Batch size (30) reached.\n",
      "2025-06-06 07:16:42,376 [INFO] root.__labeling: Updated the labels at: /home/stevance/Data/FinkZTFStream/labeled.csv\n",
      "2025-06-06 07:16:42,377 [INFO] root.__init__: Saved training ids locally to /home/stevance/Science/fink-vra-notebooks/test_outputs/teeeeest/uncertainty_gal_training_ids.csv\n",
      "2025-06-06 07:16:42,379 [INFO] finkvra.alonstream.alpipeline.__init__: Made y_train and X_train and saved to /home/stevance/Science/fink-vra-notebooks/test_outputs/teeeeest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run round_0_uncertainty at: http://127.0.0.1:6969/#/experiments/289037665776575127/runs/59abe7e8978744adb41fee550d6774d5\n",
      "🧪 View experiment at: http://127.0.0.1:6969/#/experiments/289037665776575127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stevance/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but HistGradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "alpipe = ALPipeline(configfile='./testconfigfile.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bf278126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([3072422580115015006, 3070413571415015007, 3070410155015010015,\n",
       "       3070411124115015013, 3070413103215015021, 3070412070215015010,\n",
       "       3070412555215015027, 3070413104315015004, 3072421642915015021,\n",
       "       3070420854615015025, 3070411124115015020, 3070419441815015028,\n",
       "       3070413103915015007, 3070419442415015034, 3070418963915015013,\n",
       "       3070419905315015028, 3070421792715015016, 3070420384315015019,\n",
       "       3070410150515015030, 3070412552515015017, 3072422112215015019,\n",
       "       3070413574215015021, 3070410643715015019, 3072414510615010007,\n",
       "       3070422264115015010, 3070414060515015001, 3069382583515015017,\n",
       "       3070410153515015003, 3072417854015015021, 3072419752615015008],\n",
       "      dtype='int64', name='candid')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpipe.candid_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3137bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
